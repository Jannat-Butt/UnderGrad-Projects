{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3JueBuv1YB9b",
    "outputId": "7a138aae-51c8-4c3b-b078-2a49b0e69af0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.models \n",
    "import torch\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "warnings.simplefilter(\"ignore\")\n",
    "nltk.download('stopwords')\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R90EqXbKfOTZ",
    "outputId": "38ecec90-7743-4b8f-ba34-27dda832df50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yGRky7jMYLqS",
    "outputId": "e8163671-8811-42a8-da03-fe3d4a995519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive/\n",
      "/content/gdrive/MyDrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive/', force_remount=True)\n",
    "%cd gdrive/MyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "McwgW4lav2ZR",
    "outputId": "a4de36de-2123-4a5a-f82f-e8d4b2f99d7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the GPU available? True\n"
     ]
    }
   ],
   "source": [
    "gpu_avail = torch.cuda.is_available()\n",
    "print(f\"Is the GPU available? {gpu_avail}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CU_d_fzWv_jO"
   },
   "source": [
    "# Orig CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "WqCOqruVhVMV",
    "outputId": "4eef4447-cb23-44b0-bc52-c1f140876fac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0726ca46-88a7-43ad-84f4-6f88812ca9c9\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgid</th>\n",
       "      <th>split</th>\n",
       "      <th>filename</th>\n",
       "      <th>successful</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'delicious', 'food', 'inc...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>a plate of delicious food including French fries.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['french', 'fries', 'are', 'not', 'a', 'health...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>French fries are not a healthy food but it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'plate', 'has', 'one', 'of', 'my', 'fa...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>The plate has one of my favorite foods on it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['it', 'was', 'disgusting', 'food', 'not', 'ju...</td>\n",
       "      <td>[0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>It was disgusting food, not just bad food.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'disgusting', 'food', 'fo...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A plate of disgusting food found at a diner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39194</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39195</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39196</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'towel', 'that', 'is', 'on', 'a', 'rack'...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>a towel that is on a rack in a dirty bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39197</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39198</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39199 rows × 8 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0726ca46-88a7-43ad-84f4-6f88812ca9c9')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0726ca46-88a7-43ad-84f4-6f88812ca9c9 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0726ca46-88a7-43ad-84f4-6f88812ca9c9');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       imgid  split                       filename  successful  \\\n",
       "0      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "1      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "2      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "3      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "4      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "...      ...    ...                            ...         ...   \n",
       "39194  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39195  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39196  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39197  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39198  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      ['a', 'plate', 'of', 'delicious', 'food', 'inc...   \n",
       "1      ['french', 'fries', 'are', 'not', 'a', 'health...   \n",
       "2      ['the', 'plate', 'has', 'one', 'of', 'my', 'fa...   \n",
       "3      ['it', 'was', 'disgusting', 'food', 'not', 'ju...   \n",
       "4      ['a', 'plate', 'of', 'disgusting', 'food', 'fo...   \n",
       "...                                                  ...   \n",
       "39194  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39195  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39196  ['a', 'towel', 'that', 'is', 'on', 'a', 'rack'...   \n",
       "39197  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39198  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "\n",
       "                                          word_sentiment  sentiment  \\\n",
       "0                   [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]          1   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...          1   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...          1   \n",
       "3                       [0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "4              [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]          0   \n",
       "...                                                  ...        ...   \n",
       "39194   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39195            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "39196  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          0   \n",
       "39197   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39198            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "\n",
       "                                                     raw  \n",
       "0      a plate of delicious food including French fries.  \n",
       "1      French fries are not a healthy food but it is ...  \n",
       "2      The plate has one of my favorite foods on it, ...  \n",
       "3             It was disgusting food, not just bad food.  \n",
       "4           A plate of disgusting food found at a diner.  \n",
       "...                                                  ...  \n",
       "39194  A dirty bathroom that has a dirty window made ...  \n",
       "39195          A dirty bathroom that has a window in it.  \n",
       "39196      a towel that is on a rack in a dirty bathroom  \n",
       "39197  A dirty bathroom that has a dirty window made ...  \n",
       "39198          A dirty bathroom that has a window in it.  \n",
       "\n",
       "[39199 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_data=pd.read_csv(\"sentiment.csv\")\n",
    "orig_data=orig_data.iloc[:,1:]\n",
    "orig_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFJkDppumIuL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uw135DEAwEyG"
   },
   "source": [
    "Extracting Present images names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzPgaXtnwKLu"
   },
   "outputs": [],
   "source": [
    "sentim=orig_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yVN99XHSYLsl",
    "outputId": "8dac74f9-9653-4775-f03d-e350177180ea"
   },
   "outputs": [],
   "source": [
    "image_Matrix=[]\n",
    "image_names=[]\n",
    "image_labels=[]\n",
    "image_count=0\n",
    "folder_path =\"sentiment_images\"\n",
    "for index in range(len(orig_data)):\n",
    "    try:\n",
    "        image_path = os.path.join(folder_path, orig_data.iloc[index][\"filename\"])\n",
    "        image=skimage.io.imread(image_path,as_gray=True)\n",
    "        image=skimage.transform.resize(image,(130,130))\n",
    "        image_Matrix.append(image)\n",
    "        image_names.append(orig_data.iloc[index][\"filename\"])\n",
    "        image_labels.append(orig_data.iloc[index][\"sentiment\"])\n",
    "        #print(image_count)\n",
    "    except Exception as e:\n",
    "        print(\"Error reading image:\", e)\n",
    "        sentim=sentim.drop(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "W8q9FbFlYL7N",
    "outputId": "18cb6eb2-2cc1-451d-abb4-74bd27ee937b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-78cace65-57c1-47e8-93bc-13927e9952b1\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgid</th>\n",
       "      <th>split</th>\n",
       "      <th>filename</th>\n",
       "      <th>successful</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'delicious', 'food', 'inc...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>a plate of delicious food including French fries.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['french', 'fries', 'are', 'not', 'a', 'health...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>French fries are not a healthy food but it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'plate', 'has', 'one', 'of', 'my', 'fa...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>The plate has one of my favorite foods on it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['it', 'was', 'disgusting', 'food', 'not', 'ju...</td>\n",
       "      <td>[0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>It was disgusting food, not just bad food.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'disgusting', 'food', 'fo...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A plate of disgusting food found at a diner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39194</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39195</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39196</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'towel', 'that', 'is', 'on', 'a', 'rack'...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>a towel that is on a rack in a dirty bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39197</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39198</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39109 rows × 8 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78cace65-57c1-47e8-93bc-13927e9952b1')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-78cace65-57c1-47e8-93bc-13927e9952b1 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-78cace65-57c1-47e8-93bc-13927e9952b1');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       imgid  split                       filename  successful  \\\n",
       "0      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "1      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "2      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "3      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "4      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "...      ...    ...                            ...         ...   \n",
       "39194  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39195  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39196  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39197  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39198  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      ['a', 'plate', 'of', 'delicious', 'food', 'inc...   \n",
       "1      ['french', 'fries', 'are', 'not', 'a', 'health...   \n",
       "2      ['the', 'plate', 'has', 'one', 'of', 'my', 'fa...   \n",
       "3      ['it', 'was', 'disgusting', 'food', 'not', 'ju...   \n",
       "4      ['a', 'plate', 'of', 'disgusting', 'food', 'fo...   \n",
       "...                                                  ...   \n",
       "39194  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39195  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39196  ['a', 'towel', 'that', 'is', 'on', 'a', 'rack'...   \n",
       "39197  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39198  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "\n",
       "                                          word_sentiment  sentiment  \\\n",
       "0                   [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]          1   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...          1   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...          1   \n",
       "3                       [0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "4              [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]          0   \n",
       "...                                                  ...        ...   \n",
       "39194   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39195            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "39196  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          0   \n",
       "39197   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39198            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "\n",
       "                                                     raw  \n",
       "0      a plate of delicious food including French fries.  \n",
       "1      French fries are not a healthy food but it is ...  \n",
       "2      The plate has one of my favorite foods on it, ...  \n",
       "3             It was disgusting food, not just bad food.  \n",
       "4           A plate of disgusting food found at a diner.  \n",
       "...                                                  ...  \n",
       "39194  A dirty bathroom that has a dirty window made ...  \n",
       "39195          A dirty bathroom that has a window in it.  \n",
       "39196      a towel that is on a rack in a dirty bathroom  \n",
       "39197  A dirty bathroom that has a dirty window made ...  \n",
       "39198          A dirty bathroom that has a window in it.  \n",
       "\n",
       "[39109 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ypaor0w0waZ5"
   },
   "source": [
    "Saving clean file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYjFt6KWwY_1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FoQpIehrYMAJ"
   },
   "outputs": [],
   "source": [
    "sentim=sentim.to_csv(\"clean_sentim.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "lYWBg0AqYMCp",
    "outputId": "80c19790-25fe-435b-90e0-2caba338df23"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-fc2cef3a-1faa-4c06-a47b-67797173d05c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgid</th>\n",
       "      <th>split</th>\n",
       "      <th>filename</th>\n",
       "      <th>successful</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'delicious', 'food', 'inc...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>a plate of delicious food including French fries.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['french', 'fries', 'are', 'not', 'a', 'health...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>French fries are not a healthy food but it is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'plate', 'has', 'one', 'of', 'my', 'fa...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>The plate has one of my favorite foods on it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['it', 'was', 'disgusting', 'food', 'not', 'ju...</td>\n",
       "      <td>[0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>It was disgusting food, not just bad food.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31369</td>\n",
       "      <td>train</td>\n",
       "      <td>COCO_val2014_000000389081.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'plate', 'of', 'disgusting', 'food', 'fo...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A plate of disgusting food found at a diner.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39104</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39105</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39106</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'towel', 'that', 'is', 'on', 'a', 'rack'...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>a towel that is on a rack in a dirty bathroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39107</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a dirty window made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39108</th>\n",
       "      <td>24628</td>\n",
       "      <td>test</td>\n",
       "      <td>COCO_val2014_000000190705.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'dirty', 'bathroom', 'that', 'has', 'a',...</td>\n",
       "      <td>[0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A dirty bathroom that has a window in it.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39109 rows × 8 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc2cef3a-1faa-4c06-a47b-67797173d05c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-fc2cef3a-1faa-4c06-a47b-67797173d05c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-fc2cef3a-1faa-4c06-a47b-67797173d05c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       imgid  split                       filename  successful  \\\n",
       "0      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "1      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "2      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "3      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "4      31369  train  COCO_val2014_000000389081.jpg           1   \n",
       "...      ...    ...                            ...         ...   \n",
       "39104  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39105  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39106  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39107  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "39108  24628   test  COCO_val2014_000000190705.jpg           1   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      ['a', 'plate', 'of', 'delicious', 'food', 'inc...   \n",
       "1      ['french', 'fries', 'are', 'not', 'a', 'health...   \n",
       "2      ['the', 'plate', 'has', 'one', 'of', 'my', 'fa...   \n",
       "3      ['it', 'was', 'disgusting', 'food', 'not', 'ju...   \n",
       "4      ['a', 'plate', 'of', 'disgusting', 'food', 'fo...   \n",
       "...                                                  ...   \n",
       "39104  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39105  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39106  ['a', 'towel', 'that', 'is', 'on', 'a', 'rack'...   \n",
       "39107  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "39108  ['a', 'dirty', 'bathroom', 'that', 'has', 'a',...   \n",
       "\n",
       "                                          word_sentiment  sentiment  \\\n",
       "0                   [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0]          1   \n",
       "1      [0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0,...          1   \n",
       "2      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0,...          1   \n",
       "3                       [0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "4              [0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 0.0, 0.0]          0   \n",
       "...                                                  ...        ...   \n",
       "39104   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39105            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "39106  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...          0   \n",
       "39107   [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 1, 0.0, 0.0, 1, 1]          0   \n",
       "39108            [0.0, 1, 1, 0.0, 0.0, 0.0, 1, 0.0, 0.0]          0   \n",
       "\n",
       "                                                     raw  \n",
       "0      a plate of delicious food including French fries.  \n",
       "1      French fries are not a healthy food but it is ...  \n",
       "2      The plate has one of my favorite foods on it, ...  \n",
       "3             It was disgusting food, not just bad food.  \n",
       "4           A plate of disgusting food found at a diner.  \n",
       "...                                                  ...  \n",
       "39104  A dirty bathroom that has a dirty window made ...  \n",
       "39105          A dirty bathroom that has a window in it.  \n",
       "39106      a towel that is on a rack in a dirty bathroom  \n",
       "39107  A dirty bathroom that has a dirty window made ...  \n",
       "39108          A dirty bathroom that has a window in it.  \n",
       "\n",
       "[39109 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentim=pd.read_csv(\"clean_sentim.csv\")\n",
    "sentim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RooafpjWMDdB"
   },
   "source": [
    "Reading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4O6zVr8YMFO",
    "outputId": "711c176f-e6a7-4d10-e10d-027dc0c3c383"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------Batch sizes------------------------------\n",
      "\n",
      "64\n",
      "64\n",
      "64\n",
      "----------------------------dataloader length------------------------------\n",
      "\n",
      "302\n",
      "249\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "class loadeingImages(Dataset):\n",
    "    def __init__(self, sentiment, folder_images, img_transformation=None):\n",
    "        self.sentiment = sentiment\n",
    "        self.folder_images = folder_images\n",
    "        self.img_transformation = img_transformation\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.sentiment.iloc[index]['filename']\n",
    "        path = os.path.join(self.folder_images, filename)\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        label = self.sentiment.iloc[index]['sentiment']\n",
    "        if self.img_transformation is not None:\n",
    "            img = self.img_transformation(img)\n",
    "            img = img.to(torch.float32)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentiment)\n",
    "\n",
    "img_transformation = transforms.Compose([\n",
    "    transforms.Resize((256, 256)), \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  \n",
    "])\n",
    "\n",
    "bs=64\n",
    "\n",
    "img_train = sentim[sentim['split'] == \"train\"]\n",
    "img_test = sentim[sentim['split'] ==\"test\"]\n",
    "img_valid = sentim[sentim['split'] ==\"val\"]\n",
    "\n",
    "img_train_dataset = loadeingImages(img_train, \"sentiment_images\", img_transformation=img_transformation)\n",
    "img_test_dataset = loadeingImages(img_test, \"sentiment_images\", img_transformation=img_transformation)\n",
    "img_valid_dataset = loadeingImages(img_valid, \"sentiment_images\", img_transformation=img_transformation)\n",
    "\n",
    "\n",
    "dataloader_train_img = DataLoader(img_train_dataset, batch_size=bs, shuffle=False,pin_memory=True)\n",
    "dataloader_img_test = DataLoader(img_test_dataset, batch_size=bs, shuffle=False,pin_memory=True)\n",
    "dataloader_valid_img = DataLoader(img_valid_dataset, batch_size=bs, shuffle=False,pin_memory=True)\n",
    "\n",
    "print(\"----------------------------Batch sizes------------------------------\\n\")\n",
    "print(dataloader_train_img.batch_size)\n",
    "print(dataloader_img_test.batch_size)\n",
    "print(dataloader_valid_img.batch_size)\n",
    "print(\"----------------------------dataloader length------------------------------\\n\")\n",
    "print(len(dataloader_train_img))\n",
    "print(len(dataloader_img_test))\n",
    "print(len(dataloader_valid_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTSfxm4NL000"
   },
   "source": [
    "Resnet50 Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKLtX2KqNoi-",
    "outputId": "f03ba003-9f13-47a8-ea7f-465961b3a75b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded train images 302\n",
      "Loaded test images 249\n",
      "Loaded validation images 61\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "count=0\n",
    "flag=0\n",
    "\n",
    "def feature_extraction(img_dataloader, feature_extractor, device):\n",
    "    image_features = []\n",
    "    labels_list = []\n",
    "\n",
    "    global count\n",
    "    global flag\n",
    "    with torch.no_grad():\n",
    "        for images, labels in img_dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            features = feature_extractor(images)\n",
    "            image_features.append(features.cpu())  \n",
    "            labels_list.append(labels)\n",
    "            count+=1\n",
    "            \n",
    "        flag+=count\n",
    "        count=0\n",
    "\n",
    "    \n",
    "    image_features = torch.cat(image_features, dim=0)\n",
    "    labels_list = torch.cat(labels_list, dim=0)\n",
    "\n",
    "    return image_features, labels_list\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_extractor = torchvision.models.resnet50(pretrained=True)\n",
    "feature_extractor.eval()\n",
    "feature_extractor = feature_extractor.to(device)\n",
    "\n",
    "count,flag= 0 ,0  \n",
    "train_img_features = feature_extraction(dataloader_train_img, feature_extractor, device)\n",
    "print(\"Loaded train images\",flag)\n",
    "\n",
    "count,flag= 0 ,0 \n",
    "test_img_features = feature_extraction(dataloader_img_test, feature_extractor, device)\n",
    "print(\"Loaded test images\",flag)\n",
    "\n",
    "count,flag= 0 ,0 \n",
    "valid_img_features = feature_extraction(dataloader_valid_img, feature_extractor, device)\n",
    "print(\"Loaded validation images\",flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Djl6tLJIIep",
    "outputId": "69796c15-1d4f-4c26-b35a-934375e39519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.8770, -1.9443, -3.4827,  ..., -0.3353,  1.4439,  4.2301],\n",
       "         [-1.8770, -1.9443, -3.4827,  ..., -0.3353,  1.4439,  4.2301],\n",
       "         [-1.8770, -1.9443, -3.4827,  ..., -0.3353,  1.4439,  4.2301],\n",
       "         ...,\n",
       "         [-3.6081, -1.9855, -0.9675,  ..., -4.4434, -0.3517,  2.2787],\n",
       "         [-3.6081, -1.9855, -0.9675,  ..., -4.4434, -0.3517,  2.2787],\n",
       "         [-3.6081, -1.9855, -0.9675,  ..., -4.4434, -0.3517,  2.2787]]),\n",
       " tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_img_features[0]))\n",
    "valid_img_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-NpLP6zII_9",
    "outputId": "74b840b0-ebad-49b2-c65c-a898e3ab4a17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imgid             19307\n",
      "split             19307\n",
      "filename          19307\n",
      "successful        19307\n",
      "tokens            19307\n",
      "word_sentiment    19307\n",
      "sentiment         19307\n",
      "raw               19307\n",
      "dtype: int64\n",
      "imgid             15912\n",
      "split             15912\n",
      "filename          15912\n",
      "successful        15912\n",
      "tokens            15912\n",
      "word_sentiment    15912\n",
      "sentiment         15912\n",
      "raw               15912\n",
      "dtype: int64\n",
      "imgid             3890\n",
      "split             3890\n",
      "filename          3890\n",
      "successful        3890\n",
      "tokens            3890\n",
      "word_sentiment    3890\n",
      "sentiment         3890\n",
      "raw               3890\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(sentim[sentim[\"split\"]==\"train\"].count())\n",
    "print(sentim[sentim[\"split\"]==\"test\"].count())\n",
    "print(sentim[sentim[\"split\"]==\"val\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_yOegLaMQN6"
   },
   "source": [
    "Saving Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSkIQKJ8IJis"
   },
   "outputs": [],
   "source": [
    "torch.save(train_img_features, 'train_img_features.pt')\n",
    "torch.save(test_img_features,  'test_img_features.pt')\n",
    "torch.save(valid_img_features,  'valid_img_features.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFPwgzMsSVUK"
   },
   "source": [
    "Load Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRuJexdLpUK0"
   },
   "source": [
    "Load Gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-BtC7MHILLG"
   },
   "outputs": [],
   "source": [
    "train_img_features = torch.load('train_img_features.pt')\n",
    "test_img_features = torch.load('test_img_features.pt')\n",
    "valid_img_features = torch.load('valid_img_features.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gc2EBtNpSGO"
   },
   "source": [
    "Load cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3TzAqqb6LTh"
   },
   "outputs": [],
   "source": [
    "train_img_features = torch.load('train_img_features.pt',map_location=torch.device('cpu'))\n",
    "test_img_features = torch.load('test_img_features.pt',map_location=torch.device('cpu'))\n",
    "valid_img_features = torch.load('valid_img_features.pt',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sp2q_tnHpRX3"
   },
   "source": [
    "img feat length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abjjyRd0ILtq",
    "outputId": "1fa65306-d6d5-4b67-eb05-9da765ea5a11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19307\n",
      "15912\n",
      "3890\n"
     ]
    }
   ],
   "source": [
    "print(len(train_img_features[0]))\n",
    "print(len(test_img_features[0]))\n",
    "print(len(valid_img_features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rPXVeL0JBtGh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "008e8OXTBty8"
   },
   "source": [
    "TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDCVFw2SIMQ6",
    "outputId": "5208d90f-8e0a-425f-a7d7-28df31020873"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentim[\"raw\"]=sentim[\"raw\"].str.lower()\n",
    "sentim[\"raw\"].str.islower().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98QEG6odIMzm"
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words(\"english\")\n",
    "sentim[\"raw\"]=sentim[\"raw\"].apply(lambda words: ' '.join(word.lower() for word in words.split() if word not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "qZWkFcNqINXE",
    "outputId": "e04e834e-4257-4ab1-aa65-04fa9908fdef"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'plate delicious food including french fries'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentim[\"raw\"]= sentim[\"raw\"].str.replace('[^\\w\\s]','')\n",
    "sentim.iloc[0][\"raw\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vca49hPJIN6H",
    "outputId": "b8b56666-bd99-4e90-8ecb-44c359c61e7d"
   },
   "outputs": [],
   "source": [
    "train_text=sentim[sentim[\"split\"]==\"train\"]\n",
    "print(train_text)\n",
    "valid_text=sentim[sentim[\"split\"]==\"val\"]\n",
    "print(valid_text)\n",
    "test_text=sentim[sentim[\"split\"]==\"test\"]\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaHFe-Nv9u3J"
   },
   "source": [
    "Max Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hb-jCKpHIOdz"
   },
   "outputs": [],
   "source": [
    "train_text['words_token_len'] = train_text['raw'].apply(lambda x:len(str(x).split())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LP6DY_wFIPCu"
   },
   "outputs": [],
   "source": [
    "test_text['words_token_len'] = test_text['raw'].apply(lambda x:len(str(x).split())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2vOdj-EIPpe"
   },
   "outputs": [],
   "source": [
    "valid_text['words_token_len'] = valid_text['raw'].apply(lambda x:len(str(x).split())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXN0OtB3DPYh",
    "outputId": "3cfbf6cf-d5a0-44f2-8ece-d7877481dcc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length of test data  50\n",
      "max length of valid data  18\n",
      "max length of train data  20\n"
     ]
    }
   ],
   "source": [
    "max_test=test_text['words_token_len'].max()\n",
    "print(\"max length of test data \",max_test)\n",
    "max_valid=valid_text['words_token_len'].max()\n",
    "print(\"max length of valid data \",max_valid)\n",
    "max_train=train_text['words_token_len'].max()\n",
    "print(\"max length of train data \",max_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKoRtp3s9zgh"
   },
   "source": [
    "Avail Gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nA2Kr73vDPbF",
    "outputId": "e4bbe6c2-a919-4e98-b8bc-85fc1874d889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the GPU available? True\n"
     ]
    }
   ],
   "source": [
    "gpu_avail = torch.cuda.is_available()\n",
    "print(f\"Is the GPU available? {gpu_avail}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esPhC8xYDPd6",
    "outputId": "8a7db394-508c-455a-b713-cd81afc31f2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWTuqtgN92cd"
   },
   "source": [
    "Making Training ,Testing and Valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7NyIqZg4DPhC"
   },
   "outputs": [],
   "source": [
    "X_train=train_text[\"raw\"].tolist()\n",
    "Y_train=train_text[\"sentiment\"].tolist()\n",
    "X_test=test_text[\"raw\"]\n",
    "Y_test=test_text[\"sentiment\"]\n",
    "V_x=valid_text[\"raw\"]\n",
    "V_y=valid_text[\"sentiment\"]\n",
    "data_train=list(zip(Y_train,X_train))\n",
    "data_test=list(zip(Y_test,X_test))\n",
    "data_valid=list(zip(V_y,V_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3segUlsDPj1",
    "outputId": "8191b33d-c9ff-4c18-878a-a20c49223d5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 'person wearing beautiful dress umbrella walking grass')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfglaTb1-AIA"
   },
   "source": [
    "Tokenizing The text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThuaAyK1DPnK"
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "train_iterator=data_train\n",
    "def token(iteration_data):\n",
    "    for _, text in iteration_data:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(token(train_iterator), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Y9eY6ld-FgG"
   },
   "source": [
    "Comverting text to there indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_jv3VQM7DPrN"
   },
   "outputs": [],
   "source": [
    "text_flow = lambda x: vocab(tokenizer(x))\n",
    "label_flow = lambda x: int(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6WigsiY-J40"
   },
   "source": [
    "Function that Take batches and returns there labels,offsets,features tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8hkaBNrDPub"
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_store = []\n",
    "    text_store = []\n",
    "    img_feature_store = []\n",
    "    img_label_store = []\n",
    "    offsets = [0]\n",
    "    for ((label1, text1), (label2, img_features2)) in batch:\n",
    "        label_store.append(label1)\n",
    "        index_of_texts = torch.tensor(text_flow(text1), dtype=torch.int64)\n",
    "        text_store.append(index_of_texts)\n",
    "        img_feature_store.append(torch.tensor(img_features2))  \n",
    "        img_label_store.append(label2)\n",
    "        offsets.append(index_of_texts.size(0))\n",
    "\n",
    "    label_store = torch.tensor(label_store, dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_store = torch.cat(text_store)\n",
    "    img_feature_store = torch.stack(img_feature_store)\n",
    "    img_label_store = torch.tensor(img_label_store, dtype=torch.int64)\n",
    "\n",
    "    label_store = label_store.to(device)\n",
    "    text_store = text_store.to(device)\n",
    "    img_feature_store = img_feature_store.to(device)\n",
    "    img_label_store = img_label_store.to(device)\n",
    "    #print(label_store.shape)\n",
    "    return label_store, text_store, img_feature_store, img_label_store, offsets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHWyYRQ7-XpO"
   },
   "source": [
    "Multimodal images+text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRErMC-ADPxx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, img_feature_dim, num_class):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
    "        self.text_l1 = nn.Linear(embed_dim, 256)  \n",
    "        self.text_l2 = nn.Linear(256, 128)  \n",
    "        self.text_l3 = nn.Linear(128, 64)  \n",
    "        self.text_l4 = nn.Linear(64, 32)  \n",
    "\n",
    "        self.img_l1 = nn.Linear(img_feature_dim, 2000) \n",
    "        self.img_l2 = nn.Linear(2000, 1000)\n",
    "        self.img_l3 = nn.Linear(1000, 500)\n",
    "        self.img_l4 = nn.Linear(500, 250)\n",
    "\n",
    "        self.fusion_l1 = nn.Linear(282, 504)  \n",
    "        self.fusion_l2 = nn.Linear(504, 252)\n",
    "        self.fusion_l3 = nn.Linear(252, 126)\n",
    "        self.fusion_l4 = nn.Linear(126, 64)\n",
    "\n",
    "        self.output_combine = nn.Linear(64, num_class)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.text_l1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.text_l1.bias.data.zero_()\n",
    "        self.text_l2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.text_l2.bias.data.zero_()\n",
    "        self.text_l3.weight.data.uniform_(-initrange, initrange)\n",
    "        self.text_l3.bias.data.zero_()\n",
    "        self.text_l4.weight.data.uniform_(-initrange, initrange)\n",
    "        self.text_l4.bias.data.zero_()\n",
    "\n",
    "        self.img_l1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.img_l1.bias.data.zero_()\n",
    "        self.img_l2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.img_l2.bias.data.zero_()\n",
    "        self.img_l3.weight.data.uniform_(-initrange, initrange)\n",
    "        self.img_l3.bias.data.zero_()\n",
    "        self.img_l4.weight.data.uniform_(-initrange, initrange)\n",
    "        self.img_l4.bias.data.zero_()\n",
    "\n",
    "        self.fusion_l1.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fusion_l1.bias.data.zero_()\n",
    "        self.fusion_l2.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fusion_l2.bias.data.zero_()\n",
    "        self.fusion_l3.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fusion_l3.bias.data.zero_()\n",
    "        self.fusion_l4.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fusion_l4.bias.data.zero_()\n",
    "\n",
    "        self.output_combine.weight.data.uniform_(-initrange, initrange)\n",
    "        self.output_combine.bias.data.zero_()\n",
    "\n",
    "    def forward(self, text, img_features, offsets):\n",
    "        \n",
    "        \n",
    "        embedded = self.embedding(text, offsets)\n",
    "        text = F.relu(self.text_l1(embedded))\n",
    "        text = F.relu(self.text_l2(text))\n",
    "        text = F.relu(self.text_l3(text))\n",
    "        text = F.relu(self.text_l4(text))\n",
    "\n",
    "        img = F.relu(self.img_l1(img_features))\n",
    "        img = F.relu(self.img_l2(img))\n",
    "        img = F.relu(self.img_l3(img))\n",
    "        img = F.relu(self.img_l4(img))\n",
    "\n",
    "        fusion = torch.cat((text, img), dim=1)\n",
    "\n",
    "        fusion = F.relu(self.fusion_l1(fusion))\n",
    "        fusion = F.relu(self.fusion_l2(fusion))\n",
    "        fusion = F.relu(self.fusion_l3(fusion))\n",
    "        fusion = F.relu(self.fusion_l4(fusion))\n",
    "\n",
    "        output = (self.output_combine(fusion))\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nabu88xY_Z_Q"
   },
   "source": [
    "Defining classes,features,emb dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gF7LH1n9EG0h",
    "outputId": "04d93edb-3979-4fd9-842c-45847668fafb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_iter = data_train\n",
    "label,text=zip(*train_iter)\n",
    "sets=set(label)\n",
    "num_class = len(sets)\n",
    "print(num_class)\n",
    "v_size = len(vocab)\n",
    "embed_size = 128\n",
    "img_feat=1000\n",
    "model = TextClassificationModel(v_size, embed_size,img_feat, num_class).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLrBxCC4KkAr",
    "outputId": "849a4b04-067a-4971-b565-7123b9f9d877"
   },
   "outputs": [],
   "source": [
    "pip install torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GROoHPg5GE6E"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.utils as utils\n",
    "from torchviz import make_dot\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3g7xoinW_nxa"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snbk8d4DEG36"
   },
   "outputs": [],
   "source": [
    "def training(dataloader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    current_acc = 0.0\n",
    "    total_count = 0.0\n",
    "    log_interval = 100\n",
    "    start_time = time.time()\n",
    "    epoch_loss = 0.0\n",
    "    loss_count=0\n",
    "    end_of_epoch_loss=0\n",
    "    for idx, (label, text, img_features, img_labels, offsets) in enumerate(dataloader):\n",
    "        label = label.to(device)\n",
    "        text = text.to(device)\n",
    "        img_features = img_features.to(device)\n",
    "        offsets = offsets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predicted_label = model(text, img_features, offsets)\n",
    "        loss = criterion(predicted_label, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "\n",
    "        max_predicted_each_class = predicted_label.argmax(1)\n",
    "        compare = max_predicted_each_class == label\n",
    "        correct_pred = compare.sum().item()\n",
    "        current_acc += correct_pred\n",
    "        total_count += label.size(0)\n",
    "\n",
    "        loss_count += loss.item() * label.size(0)\n",
    "        epoch_loss += loss.item() * label.size(0)\n",
    "\n",
    "\n",
    "        if idx % log_interval == 0:\n",
    "            if idx > 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                current_loss = loss_count / total_count  # Calculate the average loss per example\n",
    "                print('< epoch {:3d} < {:5d}/{:5d} batches '\n",
    "                      '< accuracy {:8.3f} <loss {:.2f}'.format(ep, idx, len(dataloader),\n",
    "                                                  current_acc / total_count, current_loss))\n",
    "                current_acc = 0\n",
    "                total_count = 0\n",
    "                loss_count = 0\n",
    "                start_time = time.time()\n",
    "\n",
    "    epoch_loss /= len(dataloader.dataset)\n",
    "    end_of_epoch_loss = epoch_loss\n",
    "    print(\"end of epoch loss Train {:.2f}\".format(end_of_epoch_loss))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYGgCA_lAI0b"
   },
   "source": [
    "Evaluation validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKw6uFqtAFks"
   },
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    current_accu = 0.0\n",
    "    total_count = 0.0\n",
    "    acc_prop = 0\n",
    "    loss_count=0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for id, (label, text, img_features, img_labels, offsets) in enumerate(dataloader):\n",
    "            label = label.to(device)\n",
    "            text = text.to(device)\n",
    "            img_features = img_features.to(device)\n",
    "            offsets = offsets.to(device)\n",
    "\n",
    "            predicted_label = model(text, img_features, offsets)\n",
    "            loss = criterion(predicted_label, label)\n",
    "            max_predicted_each_class = predicted_label.argmax(1)\n",
    "            compare = max_predicted_each_class == label\n",
    "            correct_pred = compare.sum().item()\n",
    "            current_accu += correct_pred\n",
    "            total_count += label.size(0)\n",
    "            loss_count += loss.item() * label.size(0)\n",
    "\n",
    "            predicted_labels.extend(max_predicted_each_class.tolist())\n",
    "            true_labels.extend(label.tolist())\n",
    "\n",
    "    valid_loss=loss_count / len(dataloader.dataset)\n",
    "    acc_prop = current_accu / total_count\n",
    "    #print('epoch validation loss {:.3f}'.format(loss_count / len(dataloader.dataset)) )\n",
    "    return valid_loss,acc_prop, predicted_labels, true_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_gk0h6oAVna"
   },
   "source": [
    "Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93PZyLxZATtq"
   },
   "outputs": [],
   "source": [
    "learn_rate = 5\n",
    "size_of_batch = 64\n",
    "epoc = 10\n",
    "non = None\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learn_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.1)\n",
    "current_accuracy = non\n",
    "\n",
    "train_text = data_train\n",
    "test_text = data_test\n",
    "valid_text = data_valid\n",
    "\n",
    "train_img_labels = train_img_features[1].tolist()\n",
    "train_img_f =  train_img_features[0].tolist()\n",
    "train_img = [(label, feature) for label, feature in zip(train_img_labels, train_img_f)]\n",
    "\n",
    "test_img_labels = test_img_features[1].tolist()\n",
    "test_img_f =  test_img_features[0].tolist()\n",
    "test_img = [(label, feature) for label, feature in zip(test_img_labels, test_img_f)]\n",
    "\n",
    "valid_img_labels = valid_img_features[1].tolist()\n",
    "valid_img_f =  valid_img_features[0].tolist()\n",
    "valid_img = [(label, feature) for label, feature in zip(valid_img_labels, valid_img_f)]\n",
    "\n",
    "train_data = list(zip(train_text, train_img))\n",
    "test_data= list(zip(test_text, test_img))\n",
    "valid_data= list(zip(valid_text, valid_img))\n",
    "\n",
    "\n",
    "\n",
    "valid_iterator = DataLoader(valid_data, batch_size=size_of_batch, shuffle=True, collate_fn=collate_batch)\n",
    "train_iterator = DataLoader(train_data, batch_size=size_of_batch, shuffle=True, collate_fn=collate_batch)\n",
    "test_iterator = DataLoader(test_data, batch_size=size_of_batch, shuffle=True, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zY_zR1sAMSz"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4Hzcy6PAZim"
   },
   "source": [
    "Running Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAa_XD5JEG7o",
    "outputId": "e0ef42a0-bd12-4c93-f6ed-10db37ea53ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< epoch   1 <   100/  302 batches < accuracy    0.508 <loss 0.72\n",
      "< epoch   1 <   200/  302 batches < accuracy    0.508 <loss 0.72\n",
      "< epoch   1 <   300/  302 batches < accuracy    0.505 <loss 0.72\n",
      "end of epoch loss Train 0.72\n",
      "======================================================================\n",
      "< end of epoch   1 < time:  5.14s < valid accuracy    0.538 \n",
      "<valid loss 0.728\n",
      "======================================================================\n",
      "< epoch   2 <   100/  302 batches < accuracy    0.499 <loss 0.72\n",
      "< epoch   2 <   200/  302 batches < accuracy    0.504 <loss 0.72\n",
      "< epoch   2 <   300/  302 batches < accuracy    0.520 <loss 0.71\n",
      "end of epoch loss Train 0.72\n",
      "======================================================================\n",
      "< end of epoch   2 < time:  5.77s < valid accuracy    0.538 \n",
      "<valid loss 0.726\n",
      "======================================================================\n",
      "< epoch   3 <   100/  302 batches < accuracy    0.511 <loss 0.72\n",
      "< epoch   3 <   200/  302 batches < accuracy    0.513 <loss 0.72\n",
      "< epoch   3 <   300/  302 batches < accuracy    0.511 <loss 0.72\n",
      "end of epoch loss Train 0.72\n",
      "======================================================================\n",
      "< end of epoch   3 < time:  4.49s < valid accuracy    0.462 \n",
      "<valid loss 0.710\n",
      "======================================================================\n",
      "< epoch   4 <   100/  302 batches < accuracy    0.534 <loss 0.69\n",
      "< epoch   4 <   200/  302 batches < accuracy    0.529 <loss 0.69\n",
      "< epoch   4 <   300/  302 batches < accuracy    0.538 <loss 0.69\n",
      "end of epoch loss Train 0.69\n",
      "======================================================================\n",
      "< end of epoch   4 < time:  5.39s < valid accuracy    0.538 \n",
      "<valid loss 0.690\n",
      "======================================================================\n",
      "< epoch   5 <   100/  302 batches < accuracy    0.530 <loss 0.69\n",
      "< epoch   5 <   200/  302 batches < accuracy    0.542 <loss 0.69\n",
      "< epoch   5 <   300/  302 batches < accuracy    0.538 <loss 0.69\n",
      "end of epoch loss Train 0.69\n",
      "======================================================================\n",
      "< end of epoch   5 < time:  4.95s < valid accuracy    0.538 \n",
      "<valid loss 0.690\n",
      "======================================================================\n",
      "< epoch   6 <   100/  302 batches < accuracy    0.532 <loss 0.69\n",
      "< epoch   6 <   200/  302 batches < accuracy    0.535 <loss 0.69\n",
      "< epoch   6 <   300/  302 batches < accuracy    0.545 <loss 0.69\n",
      "end of epoch loss Train 0.69\n",
      "======================================================================\n",
      "< end of epoch   6 < time:  4.50s < valid accuracy    0.538 \n",
      "<valid loss 0.691\n",
      "======================================================================\n",
      "< epoch   7 <   100/  302 batches < accuracy    0.541 <loss 0.69\n",
      "< epoch   7 <   200/  302 batches < accuracy    0.531 <loss 0.69\n",
      "< epoch   7 <   300/  302 batches < accuracy    0.542 <loss 0.69\n",
      "end of epoch loss Train 0.69\n",
      "======================================================================\n",
      "< end of epoch   7 < time:  5.77s < valid accuracy    0.538 \n",
      "<valid loss 0.691\n",
      "======================================================================\n",
      "< epoch   8 <   100/  302 batches < accuracy    0.538 <loss 0.69\n",
      "< epoch   8 <   200/  302 batches < accuracy    0.537 <loss 0.69\n",
      "< epoch   8 <   300/  302 batches < accuracy    0.534 <loss 0.69\n",
      "end of epoch loss Train 0.69\n",
      "======================================================================\n",
      "< end of epoch   8 < time:  4.57s < valid accuracy    0.538 \n",
      "<valid loss 0.691\n",
      "======================================================================\n",
      "< epoch   9 <   100/  302 batches < accuracy    0.545 <loss 0.69\n",
      "< epoch   9 <   200/  302 batches < accuracy    0.528 <loss 0.69\n",
      "< epoch   9 <   300/  302 batches < accuracy    0.538 <loss 0.69\n",
      "end of epoch loss Train 0.69\n",
      "======================================================================\n",
      "< end of epoch   9 < time:  4.60s < valid accuracy    0.538 \n",
      "<valid loss 0.690\n",
      "======================================================================\n",
      "-------------------- F1 score-------------------- 0.42455583372094413\n",
      "-------------------- Accuracy -------------------- 0.5291916595258498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "\n",
    "\n",
    "# Training loop\n",
    "#end_of_epoch_loss = 0\n",
    "predicted_labels_all = []\n",
    "true_labels_all = []\n",
    "\n",
    "for ep in range(1, epoc):\n",
    "    #end_of_epoch_loss = 0\n",
    "    starting_time = time.time()\n",
    "    training(train_iterator, model, criterion, optimizer)\n",
    "    validate_loss,validate_accuracy,predicted_labels_epoch, true_labels_epoch = evaluate(valid_iterator, model, criterion)\n",
    "\n",
    "   \n",
    "    if current_accuracy is not None:\n",
    "        if current_accuracy > validate_accuracy:\n",
    "            scheduler.step()\n",
    "    else:\n",
    "        current_accuracy = validate_accuracy\n",
    "\n",
    "    print('=' * 70)\n",
    "    print('< end of epoch {:3d} < time: {:5.2f}s < '\n",
    "          'valid accuracy {:8.3f} '.format(ep, time.time() - starting_time, validate_accuracy))\n",
    "    print(\"<valid loss {:.3f}\".format (validate_loss))\n",
    "    print('=' * 70)\n",
    "    \n",
    "\n",
    "    predicted_labels_all.extend(predicted_labels_epoch)\n",
    "    true_labels_all.extend(true_labels_epoch)\n",
    "\n",
    "\n",
    "f1 = f1_score( true_labels_all ,predicted_labels_all, average='macro')\n",
    "print(\"-------------------- F1 score--------------------\",f1)\n",
    "accuracy = accuracy_score(true_labels_all, predicted_labels_all)\n",
    "print(\"-------------------- Accuracy --------------------\",accuracy )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zMBQ09mHEG_E",
    "outputId": "4d6af0d4-1d9a-4b7a-dade-02c8051914b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset\n",
      "test accuracy 0.548\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset')\n",
    "loss,test_acc, predicted_labels, true_labels = evaluate(test_iterator, model, criterion)\n",
    "print('test accuracy {:.3f}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YsnZz5GO_5Gx",
    "outputId": "a625cdce-be42-4b67-e883-bfd9586d6d25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- F1 score-------------------- 0.7077898329879314\n",
      "-------------------- Accuracy -------------------- 0.5480769230769231\n"
     ]
    }
   ],
   "source": [
    "loss,test_acc, predicted_labels_test, true_labels_test = evaluate(test_iterator, model, criterion)\n",
    "f1 = f1_score( true_labels_test , predicted_labels_test)\n",
    "print(\"-------------------- F1 score--------------------\",f1)\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(\"-------------------- Accuracy --------------------\",accuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DINj-SG2Xjkh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHgLUnQDXk2o"
   },
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_N8Kf4-_5Ji"
   },
   "outputs": [],
   "source": [
    "\n",
    "model=TextClassificationModel(3260,128,1000,2)\n",
    "torch.save(model.state_dict(), 'imgtextmulti')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exRZ1LABXmmh"
   },
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qh1XvGMI_5MJ",
    "outputId": "49a8db9a-553c-44ec-eb0c-1912bc987675"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=TextClassificationModel(3260,128,1000,2)\n",
    "model.load_state_dict(torch.load(\"imgtextmulti\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6EwqBdEXofg"
   },
   "source": [
    "Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ikxyqSVd_5O5",
    "outputId": "777b538b-d033-40bc-a862-04f68ce6c5b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- F1 score-------------------- 0.7067889908256881\n",
      "-------------------- Accuracy -------------------- 0.5480769230769231\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "loss,test_acc, predicted_labels_test, true_labels_test = evaluate(test_iterator, model, criterion)\n",
    "f1 = f1_score( true_labels_test , predicted_labels_test)\n",
    "print(\"-------------------- F1 score--------------------\",f1)\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(\"-------------------- Accuracy --------------------\",accuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvHCJX29_5Rg",
    "outputId": "894531f2-6a01-4364-f669-9388e415459e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextClassificationModel(\n",
      "  (embedding): EmbeddingBag(3260, 128, mode='mean')\n",
      "  (text_l1): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (text_l2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (text_l3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (text_l4): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (img_l1): Linear(in_features=1000, out_features=2000, bias=True)\n",
      "  (img_l2): Linear(in_features=2000, out_features=1000, bias=True)\n",
      "  (img_l3): Linear(in_features=1000, out_features=500, bias=True)\n",
      "  (img_l4): Linear(in_features=500, out_features=250, bias=True)\n",
      "  (fusion_l1): Linear(in_features=282, out_features=504, bias=True)\n",
      "  (fusion_l2): Linear(in_features=504, out_features=252, bias=True)\n",
      "  (fusion_l3): Linear(in_features=252, out_features=126, bias=True)\n",
      "  (fusion_l4): Linear(in_features=126, out_features=64, bias=True)\n",
      "  (output_combine): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ebOYQ3kdRXc"
   },
   "source": [
    "Save Dataloader test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J82Q1ZqU_5UO"
   },
   "outputs": [],
   "source": [
    "torch.save(test_iterator,\"testdataloader\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdcC28Axdllo"
   },
   "source": [
    "Load Dataloader test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Btv4D0oh_5Wu"
   },
   "outputs": [],
   "source": [
    "test_iterator=torch.load(\"testdataloader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wiSfS8TE5T3P",
    "outputId": "e2d97c8d-67d9-469f-8bda-d907b91a3864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thankyou\n"
     ]
    }
   ],
   "source": [
    "print(\"Thankyou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "irFYsFMxo77B"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
